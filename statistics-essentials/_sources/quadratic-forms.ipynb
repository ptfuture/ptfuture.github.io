{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "905cab09-88e6-49da-8285-0e87a9032377",
   "metadata": {},
   "source": [
    "# Quadratic Forms\n",
    "\n",
    "**Video lecture: https://youtu.be/2PLs3Cwt6sM**\n",
    "\n",
    "A polymonial of degree of all its terms with 2 degrees is called a **Quadratic Form**. When the coefficients of the quadratic form are real numbers, we call it the **real quadratic form**.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\sum_{i=1}^n\\sum_{j=1}^n{\\alpha_{ij}X_iX_j} \\\\\n",
    "& \\sum_{i=1}^n(X_i-\\bar{X})^2 = \\frac{n-1}{n}(X_1^2+X_2^2+...X_n^2) - \\frac{2}{n}(X_1X_2+X_1X_3+...+X_1X_n+...+X_{n-1}X_n)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "## Theorem\n",
    "\n",
    "Let $Q=Q_1+Q_2+...+Q_{k-1}+Q_k$ where $Q, Q_1,...Q_k$ are $k+1$ random variables that are real quadratic forms in terms of $n$ iid $N(\\mu, \\sigma^2)$ random variables $X_1, X_2, ... X_n$. Let $\\frac{Q}{\\sigma^2}, \\frac{Q_1}{\\sigma^2}, ..., \\frac{Q_{k-1}}{\\sigma^2}$ have $\\chi^2$ distribution with $r, r_1, ..., r_{k-1}$ degree of freedom, respectively. Let $Q_k \\ge 0$, then:\n",
    "\n",
    "- $Q_1, Q_2, ..., Q_k$ are independent and hence\n",
    "- $\\frac{Q_k}{\\sigma^2}$ has $\\chi^2(r_k)$ where $r_k = r-(r_1+...+r_{k-1})$.\n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "Let $X_{ij} \\sim N(\\mu, \\sigma^2)$ iid, $n=ab$ and \n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "X_{11}, X_{12}, ..., X_{1b} \\\\\n",
    "X_{21}, X_{22}, ..., X_{2b} \\\\\n",
    "... \\\\\n",
    "X_{a1}, X_{a2}, ..., X_{ab} \\\\\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "$\\displaystyle \\bar{X}_{..} = \\frac{\\sum_{i=1}^a\\sum_{j=1}^bX_{ij}}{ab}$, $\\displaystyle \\bar{X}_{i.} = \\frac{\\sum_{j=1}^bX_{ij}}{b}$, $\\displaystyle \\bar{X}_{.j} = \\frac{\\sum_{i=1}^aX_{ij}}{a}$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\sum_{i=1}^a\\sum_{j=1}^b(X_{ij}-\\bar{X}_{..})^2 =& \\sum_{i=1}^a\\sum_{j=1}^b(X_{ij} - \\bar{X}_{i.} + \\bar{X}_{i.} - \\bar{X}_{..})^2 \\\\\n",
    "=& \\sum_{i=1}^a\\sum_{j=1}^b(X_{ij} - \\bar{X}_{i.})^2 + b\\sum_{i=1}^a(\\bar{X}_{i.} - \\bar{X}_{..})^2 + 2\\sum_{i=1}^a\\sum_{j=1}^b(X_{ij}-\\bar{X}_{i.})(\\bar{X}_{i.}-\\bar{X}_{..})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "But $\\displaystyle \\sum_{i=1}^a\\sum_{j=1}^b(X_{ij}-\\bar{X}_{i.})(\\bar{X}_{i.}-\\bar{X}_{..}) = \\sum_{i=1}^a(\\bar{X}_{i.}-\\bar{X}_{..})(b\\bar{X}_{i.}-b\\bar{X}_{i.}) = 0$, therefore,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{i=1}^a\\sum_{j=1}^b(X_{ij}-\\bar{X}_{..})^2 =& \\sum_{i=1}^a\\sum_{j=1}^b(X_{ij} - \\bar{X}_{i.})^2 + b\\sum_{i=1}^a(\\bar{X}_{i.} - \\bar{X}_{..})^2 \\\\\n",
    "Q =& Q_1 + Q_2 (\\#eq:q1q2)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Since $Q=(ab-1)S^2$, therefore, \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{Q}{\\sigma^2} \\sim \\chi^2(ab-1) (\\#eq:qdist)\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "Because $X_{ij}$ are independent, $\\displaystyle \\frac{Q_1}{\\sigma^2} = \\sum_{i=1}^a\\sum_{j=1}^b\\frac{(X_{ij} - \\bar{X}_{i.})^2}{\\sigma^2}$ is the sum of $a$ number of independent $\\chi^2(b-1)$ r.v. $\\displaystyle \\sum_{j=1}^b\\frac{(X_{ij} - \\bar{X}_{i.})^2}{\\sigma^2} \\sim \\chi^2(b-1)$, \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{Q_1}{\\sigma^2} \\sim \\chi^2(a(b-1))\n",
    "(\\#eq:q1dist)\n",
    "\\end{equation}\n",
    "$$ \n",
    "By the Quadratic Form Theorem, \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{Q_2}{\\sigma^2} \\sim \\chi^2(a-1) (\\#eq:q2dist)\n",
    "\\end{equation}\n",
    "$$ \n",
    "\n",
    "where $a-1 = ab-1-a(b-1)$\n",
    "\n",
    "With the similar reasoning:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{i=1}^a\\sum_{j=1}^b(X_{ij}-\\bar{X}_{..})^2 =& \\sum_{j=1}^b\\sum_{i=1}^a(X_{ij} - \\bar{X}_{.j})^2 + a\\sum_{j=1}^b(\\bar{X}_{.j} - \\bar{X}_{..})^2 \\\\\n",
    "Q =& Q_3 + Q_4 (\\#eq:q3q4)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Where\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{Q_3}{\\sigma^2} \\sim \\chi^2(b(a-1)) (\\#eq:q3dist)\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{Q_4}{\\sigma^2} \\sim \\chi^2(b-1) (\\#eq:q4dist)\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "We could also rewrite $Q$ as sum of $Q_2, Q_4$ and $Q_5$ as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{i=1}^a\\sum_{j=1}^b(X_{ij}-\\bar{X}_{..})^2 =& \\sum_{i=1}^a\\sum_{j=1}^b [(\\bar{X}_{i.}-\\bar{X}_{..}) + (\\bar{X}_{.j}-\\bar{X}_{..}) + (X_{ij}-\\bar{X}_{i.}-\\bar{X}_{.j}+\\bar{X}_{..})]^2 \\notag \\\\ \n",
    "=& b\\sum_{i=1}^a(\\bar{X}_{i.}-\\bar{X}_{..})^2 + a\\sum_{j=1}^b(\\bar{X}_{.j}-\\bar{X}_{..})^2 \\notag \\\\\n",
    " &+ \\sum_{i=1}^a\\sum_{j=1}^b(X_{ij}-\\bar{X}_{i.}-\\bar{X}_{.j}+\\bar{X}_{..})^2 \\notag \\\\\n",
    "Q =& Q_2 + Q_4 + Q_5 (\\#eq:q2q4q5)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The other terms are zero because of $\\displaystyle \\sum_{i=1}^a(\\bar{X}_{i.}-\\bar{X}_{..}) = 0$, $\\displaystyle \\sum_{j=1}^b(\\bar{X}_{.j}-\\bar{X}_{..}) = 0$ and $\\displaystyle \\sum_{i=1}^a\\sum_{j=1}^b(X_{ij}-\\bar{X}_{i.})(\\bar{X}_{i.}-\\bar{X}_{..}) = \\sum_{i=1}^a(\\bar{X}_{i.}-\\bar{X}_{..})(b\\bar{X}_{i.}-b\\bar{X}_{i.}) = 0$.\n",
    "\n",
    "By the Quadratic Form theorem:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{Q_5}{\\sigma^2} \\sim \\chi^2((a-1)(b-1))\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $(a-1)(b-1) = ab-1-(a-1)-(b-1)$.\n",
    "\n",
    "\n",
    "Hypothesis testing: \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "F_{24} =& \\frac{Q_2/[\\sigma^2(a-1)]}{Q_4/[\\sigma^2(b-1)]} = \\frac{Q_2/(a-1)}{Q_4/(b-1)} \\sim F(a-1, b-1) \\\\\n",
    "F_{25} =& \\frac{Q_2/(a-1)}{Q_5/[(a-1)(b-1)]}  \\sim F(a-1, (a-1)(b-1)) \\\\\n",
    "...\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "## Normal Correlation Models\n",
    "\n",
    "\n",
    "Bivariate Normal PDF:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f(x, y) &= \\frac{1}{2\\pi\\sigma_x\\sigma_y\\sqrt{1-\\rho_{xy}^2}}exp\\bigg\\{ -\\frac{1}{2(1-\\rho_{xy}^2)} \\bigg[ \\bigg( \\frac{X-\\mu_x}{\\sigma_x}\\bigg)^2 \\\\\n",
    "&- 2\\rho_{xy}\\bigg( \\frac{X-\\mu_x}{\\sigma_x} \\bigg) \\bigg( \\frac{Y-\\mu_y}{\\sigma_y} \\bigg) + \\bigg( \\frac{Y-\\mu_y}{\\sigma_y} \\bigg)^2  \\bigg] \\bigg\\}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\rho_{xy} = \\frac{\\sigma_{xy}}{\\sigma_x\\sigma_y}$.\n",
    "\n",
    "Conditional PDF of $Y|X$:\n",
    "\n",
    "$$\n",
    "f_{y|x}(Y) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{y|x}} exp \\bigg\\{ -\\frac{1}{2} \\bigg( \\frac{Y-\\alpha_{y|x}-\\beta_{y|x}x}{\\sigma_{y|x}} \\bigg)^2  \\bigg\\}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\alpha_{y|x} &= \\mu_y - \\mu_x\\rho_{xy}\\frac{\\sigma_y}{\\sigma_x} \\\\\n",
    "\\beta_{y|x} &= \\rho_{xy}\\frac{\\sigma_y}{\\sigma_x} \\\\\n",
    "\\sigma_{y|x}^2 &= \\sigma_{y}^2(1-\\rho_{xy}^2)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The conditional pdf of $Y|X$ is also normal with mean $\\mu[Y|X] = \\alpha_{y|x}-\\beta_{y|x}x$, which is a linear function of $x$. \n",
    "Test of $\\rho_{xu} = 0$ vs $\\rho_{xy} \\ne 0$ comes down to a linear regression hypothesis test of $\\beta_{y|x} = 0$ vs $\\beta_{y|x} \\ne 0$.\n",
    "\n",
    "It can be shown that the **sample correlation coefficient** is a consistent estimator of its parameter $\\rho_{xy}$, \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{r}_{xy} = \\frac{\\sum_{i=1}^n(X_i-\\bar{X})(Y_i-\\bar{Y})}{\\sqrt{\\sum_{i=1}^n(X_i-\\bar{X})^2} \\sqrt{ \\sum_{i=1}^n(Y_i-\\bar{Y})^2 } }\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "therefore:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\beta_{y|x} &= \\rho_{xy}\\frac{\\sigma_y}{\\sigma_x}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "If we estimate $\\beta_{y|x}$ by replacing $\\rho_{xy}$ with $\\hat{\\rho_{xy}}$ and $\\sigma_x, \\sigma_y$ by its standard sample variance $s_x = \\frac{\\sum(X_i-\\bar{X})^2}{n-1}$, $s_y = \\frac{\\sum(Y_i-\\bar{Y})^2}{n-1}$, it can be shown that\n",
    "\n",
    "$$\n",
    "\\hat{\\beta_{y|x}} = \\frac{\\sum(X_i-\\bar{X})Y_i}{\\sum(X_i-\\bar{X})^2}\n",
    "$$\n",
    "\n",
    "This is equivalent to a simple linear regression problem. If we devide it by the standard sample deviation of $\\hat{\\beta_{y|x}}$ which is $s[\\hat{\\beta_{y|x}}] = \\sqrt{ \\frac{MSE}{\\sum(X_i-\\bar{X})^2} }$, where $\\text{MSE} = \\frac{\\sum(Y_i-\\hat{\\alpha_{y|x}}-\\hat{\\beta_{y|x}}(X_i-\\bar{X}))}{n-2} = \\frac{\\sum\\big(Y_i-\\bar{Y}-\\frac{\\sum(X_i-\\bar{X})Y_i}{\\sum(X_i-\\bar{X})^2}(X_i-\\bar{X})\\big)}{n-2}$. It can be shown that it's a t-distribution with $n-2$ degree of freedom:\n",
    "\n",
    "$$\n",
    "t^{*} = \\frac{\\hat{r}_{xy}\\sqrt{n-2}}{\\sqrt{1-\\hat{r}_{xy}^2}} \\sim t(n-2)\n",
    "$$\n",
    "\n",
    "- If $|t^{*}| \\le t(1-\\alpha/2; n-2)$ conclude $\\beta_{y|x} = 0$.\n",
    "- If $|t^{*}| \\gt t(1-\\alpha/2; n-2)$ conclude $\\beta_{y|x} \\ne 0$.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
