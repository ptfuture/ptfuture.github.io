{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ff6d43-8b7b-4fd8-b84c-7a571276d1d9",
   "metadata": {},
   "source": [
    "# Multivariate Normal\n",
    "\n",
    "**Video lecture: https://youtu.be/7fWUvqgUt2Y**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b3378-8ed0-4494-b976-daa3d05651e3",
   "metadata": {},
   "source": [
    "## Covariance\n",
    "\n",
    "### Theorom\n",
    "\n",
    "$Cov(AX) = A Cov(X) A'$\n",
    "\n",
    "_Proof:_\n",
    "\n",
    "$$\\begin{aligned}\n",
    " Cov(AX) & = E[(AX-A\\mu)(AX-A\\mu)'] \\\\\n",
    "         & = E[ AXX'A' - AX\\mu'A' - A\\mu X'A' + A\\mu \\mu' A']  \\\\\n",
    "         & = AE(XX')A' - AE(X)\\mu' - A\\mu E(X')A' + A\\mu \\mu' A' \\\\\n",
    "         & = AE(XX')A' - A\\mu \\mu' A'\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "\n",
    "Let $\\Sigma$ be the covariance matrix. Since it's symmetric. $\\Sigma$ can be decomposed into \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Sigma & = \\Gamma'\\Lambda\\Gamma  \\\\\n",
    "       & = \\Gamma'\\Lambda^\\frac{1}{2} \\Gamma \\Gamma' \\Lambda^\\frac{1}{2} \\Gamma           \\tag{1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "Define $\\Sigma^\\frac{1}{2}$ as: \n",
    "\n",
    "$$\n",
    "\\Sigma^\\frac{1}{2} = \\Gamma'\\Lambda^\\frac{1}{2} \\Gamma \\tag{2}\n",
    "$$\n",
    "\n",
    "We can rewrite (1) as:\n",
    "\n",
    "$$\n",
    "\\Sigma = \\Sigma^\\frac{1}{2} (\\Sigma^\\frac{1}{2})' = \\Sigma^\\frac{1}{2} \\Sigma^\\frac{1}{2}\n",
    "$$\n",
    "\n",
    "$\\Sigma^\\frac{1}{2}$ is symmetric as well as $\\Sigma$.\n",
    "\n",
    "The inverse of $\\Sigma^\\frac{1}{2}$ is:\n",
    "\n",
    "$$\n",
    "\\Sigma^{-\\frac{1}{2}} = \\Gamma'\\Lambda^{-\\frac{1}{2}} \\Gamma \\tag{3}\n",
    "$$\n",
    "\n",
    "\n",
    "Where $\\Gamma$ columns are orthnormal eigenvectors of $\\Lambda$, $\\Gamma$ is diagonal with eigenvalues of $\\Sigma$. that is $\\Lambda = diagonal(\\lambda_1, \\lambda_2,...,\\lambda_n)$, $\\lambda_1 \\ge \\lambda_2 \\ge \\lambda_3 \\ge ... \\lambda_n \\ge 0$\n",
    "\n",
    "### Property\n",
    "\n",
    "$\\Sigma$ is psd. That is $v'\\Sigma v \\ge 0$\n",
    "\n",
    "_Proof:_\n",
    "let $Y = v'X$, $Var(Y) >= 0$, but $Var(Y) = v\\Sigma v'$. \n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "\n",
    "## Moment generating function\n",
    "\n",
    "Let $Z \\sim N(\\mathbf{0},\\mathbf{I_n})$\n",
    "\n",
    "Then the pdf of $Z$ is:\n",
    "\n",
    "$$\n",
    "f(\\mathbf{z}) = \\left( \\frac{1}{2\\pi} \\right)^\\frac{n}{2}e^{-\\frac{1}{2}\\mathbf{z}'\\mathbf{z}} \\tag{4}\n",
    "$$\n",
    "\n",
    "Let: \n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\Sigma^\\frac{1}{2} \\mathbf{Z} + \\mathbf{\\mu} \\tag{5}\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\phi(\\mathbf{t}) = E[e^{\\mathbf{t'}\\mathbf{X}}] = e^{\\mathbf{t'}\\mathbf{\\mu} + \\frac{1}{2} \\mathbf{t'}\\Sigma\\mathbf{t}}\n",
    "$$\n",
    "\n",
    "\n",
    "Rewrite (4) in terms of $\\mathbf{Z} = \\Sigma^{-\\frac{1}{2}}(\\mathbf{X} - \\mathbf{\\mu})$\n",
    "\n",
    "The Jacobian\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\lvert\\frac{\\partial{Z}}{\\partial{X}}\\rvert & = \\lvert\\Sigma^{-\\frac{1}{2}}\\rvert \\\\\n",
    "& = \\lvert \\Gamma'\\rvert \\lvert \\Lambda^{-\\frac{1}{2}}\\rvert \\lvert \\Gamma\\rvert \\\\\n",
    "& = 1 \\times \\lvert \\Lambda^{-\\frac{1}{2}} \\rvert \\times 1 \\\\\n",
    "& = \\lvert \\Lambda \\rvert^{-\\frac{1}{2}} \\\\\n",
    "& = \\lvert \\Gamma'\\rvert \\lvert \\Lambda\\rvert^{-\\frac{1}{2}} \\lvert \\Gamma\\rvert \\\\\n",
    "& = \\lvert \\Sigma \\rvert^{-\\frac{1}{2}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "Apply parameters transformations with the Jacobian in (4) we we get:\n",
    "\n",
    "## Density function\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f(\\mathbf{x}) & = \\frac{1}{ \\left(2\\pi\\right)^\\frac{n}{2} \\lvert\\Sigma\\rvert^\\frac{1}{2} } e^{-\\frac{1}{2}\\left(\\Sigma^{-\\frac{1}{2}}\\left(\\mathbf{x}-\\mathbf{\\mu}\\right)\\right)'\\left(\\Sigma^{-\\frac{1}{2}}\\left(\\mathbf{x}-\\mathbf{\\mu}\\right)\\right)}  \\\\\n",
    "            & = \\frac{1}{ \\left(2\\pi\\right)^\\frac{n}{2} \\lvert\\Sigma\\rvert^\\frac{1}{2} } e^{-\\frac{1}{2}\\left(\\mathbf{x}-\\mathbf{\\mu}\\right)'\\Sigma^{-1}\\left(\\mathbf{x}-\\mathbf{\\mu}\\right)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "### How to generate Multivariate normal?\n",
    "\n",
    "- Given Covariance $\\Sigma$ and mean $\\mu$ \n",
    "- Find the eigenbases and form $\\Gamma$ and diagonal eigen value matrix $\\Gamma$. Find out $\\Sigma^\\frac{1}{2}$\n",
    "-  Generate n iid std normal vector $Z$\n",
    "-  Calculate $X = \\Sigma^\\frac{1}{2}Z + \\mu$\n",
    "\n",
    "## Theorem\n",
    "\n",
    "Given $\\dbinom{\\vec{X_1}}{\\vec{X_2}}$ normal, $\\vec{X_1}, \\vec{X_2}$ independent iff $\\Sigma_{12} = 0$\n",
    "\n",
    "\n",
    "Proof: Use MGF prove $\\phi_1\\times \\phi_2 = \\phi$\n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "\n",
    "## Theorem\n",
    "\n",
    "$X \\sim N_n(\\mathbf{\\mu}, \\Sigma)$, then $\\mathbf{Y} = \\mathbf{A}\\mathbf{X} + \\mathbf{b} \\sim N_m(\\mathbf{A\\mu+b, \\mathbf{A\\Sigma A'}})$ where $A$ is $n \\times m$ mattrix.\n",
    "\n",
    "Proof: Use MGF.\n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "## Theorem\n",
    "\n",
    "Suppose $\\mathbf{X} \\sim N_n(\\mathbf{\\mu, \\Sigma})$. $\\mathbf{X} = \\binom{X_1}{X_2}$. Then:\n",
    "\n",
    "$$\n",
    "\\mathbf{X_1}|\\mathbf{X_2} \\sim N_m(\\mathbf{\\mu_1 + \\Sigma_{12}\\Sigma_{22}^{-1}(X_2-\\mu_2)}, \\Sigma_{11}-\\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21})\n",
    "$$\n",
    "\n",
    "Proof:\n",
    "\n",
    "Write $\\mathbf{W=X_1-\\Sigma_{12}\\Sigma_{22}^{-1}X_2}$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "  W \\\\\n",
    "  X_2\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "  I_m & -\\Sigma_{12}\\Sigma_{22}^{-1} \\\\\n",
    "  O   & I_p\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "  X_1 \\\\\n",
    "  X_2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Calculate Covariance of $\\begin{bmatrix}\n",
    "  W \\\\\n",
    "  X_2\n",
    "\\end{bmatrix}$ indicates $Cov(W, X_2) = 0$. Since both multinormal, $W$ and $X_2$ are independent. $(W+\\Sigma_{12}\\Sigma_{22}^{-1}X_2) | X_2$ is the same as $X_1|X_2$.\n",
    "\n",
    "$\\blacksquare$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
