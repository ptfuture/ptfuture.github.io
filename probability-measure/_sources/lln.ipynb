{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7674ac6-cc00-43c5-bcf7-f1e42b3e511c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Laws of Large Numbers\n",
    "\n",
    "## Borel Cantelli Lemmas\n",
    "\n",
    "**Video lecture: https://youtu.be/lFl3QbMOz5k**\n",
    "\n",
    "Let $A_n \\in \\mathcal{F}$, Define:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\limsup{A_n}=\\bigcap\\limits_{m=1}^\\infty\\bigcup\\limits_{n=m}^\\infty{A_n} \\\\\n",
    "\\liminf{A_n}=\\bigcup\\limits_{m=1}^\\infty\\bigcap\\limits_{n=m}^\\infty{A_n}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$\\epsilon \\in \\limsup{A_n}$ iff for every $n$ there exist a $k \\ge n$ such that $\\epsilon \\in A_k$. If $n$ is time, $\\limsup{A_n}$ is often interpretated as the set of elements that happens infinitely many $A_n$, $\\limsup{A_n}$ is usually written as $[A_n\\text{ i.o.}]$. i.o. means infinitly often.\n",
    "\n",
    "$\\epsilon \\in \\liminf{A_n}$ iff $\\epsilon$ belongs to all but finitely many of the $A_n$. If $n$ is time, $\\liminf{A_n}$ is intepretated as the set of elements that eventually happened. $\\liminf{A_n}$ is usually written as $[A_n\\text{ e.a.}]$. e.a. means eventually all.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\bigcup\\limits_{n=m}^\\infty{A_n} \\downarrow \\limsup{A_n} \\quad \\text{as } m \\rightarrow\\infty \\\\\n",
    "&\\bigcap\\limits_{n=m}^\\infty{A_n} \\uparrow \\liminf{A_n} \\quad \\text{as } m \\rightarrow\\infty \\\\\n",
    "&\\bigcap\\limits_{k=n}^\\infty{A_k} \\subset \\bigcup\\limits_{k=m}^\\infty{A_k} \\quad \\forall n,m \\\\\n",
    "&\\liminf{A_n} \\subset \\limsup{A_n} \\\\\n",
    "&(\\limsup{A_n})^c = \\liminf{A_n^c}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$(\\limsup{A_n})^c = \\liminf{A_n^c}$ means, if $\\epsilon \\notin \\limsup{A_n}$ then we can conclude it belongs to all but finitely many $A_n^c$\n",
    "\n",
    "### First Borel Cantelli Lemma:\n",
    "\n",
    "If $\\sum\\limits_{n=1}^{\\infty}P(A_n) \\lt \\infty$ then $P(A_n\\text{ i.o.}) = 0$.\n",
    "\n",
    "_Proof:_ ${\\limsup}A_n \\subset \\bigcup_{k=m}^{\\infty}A_k$ implies $P({\\limsup}A_n) \\le P(\\bigcup_{k=m}^{\\infty}A_k) \\le \\sum\\limits_{k=m}^{\\infty}P(A_k)$. and the sum goes to $0$ when $m\\to\\infty$.\n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "### Second Borel Cantelli Lemma: \n",
    "\n",
    "Let $A_n$ is a sequence of independent events. If $\\sum\\limits_{n=1}^{\\infty}P(A_n)=\\infty$ then $P(A_n\\text{ i.o.})=1$.\n",
    "\n",
    "_Proof:_ We prove it by proving $P(A_n^c\\text{ e.a.})=0$. For $0 \\lt N \\lt M \\lt \\infty$, since $1-x \\lt e^{-x}$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(\\bigcap_{n=N}^{M}A_n^c) = \\prod_{n=M}^{M}(1-P(A_n)) \\lt e^{-\\sum_{n=N}^{M}P(A_n)} \\to 0 \\quad\\text{ as }M\\to\\infty\n",
    "\\end{align}\n",
    "$$\n",
    "So $P(\\bigcap_{n=N}^{\\infty}A_n^c) = 0$ for all $N$. Since $\\bigcap_{n=N}^{\\infty}A_n^c \\uparrow {\\liminf}A_n^c$ as $N\\to\\infty$, we get $\\lim\\limits_{N\\to\\infty}{P(\\bigcap_{n=N}^{\\infty}A_n^c)} = P({\\liminf}A_n^c) = 0$\n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "## Strong Law of Large numbers\n",
    "\n",
    "**Video lecture: https://youtu.be/iV2O8lam4rc**\n",
    "\n",
    "### Theorem: Strong law of large numbers\n",
    "\n",
    "Let $X_1,X_2...$ be pairwise indepedent, identically distributed r.v. with $E|X_k| \\lt \\infty$. Let $EX_k=\\mu$, $S_n=\\sum_{k=1}^nX_k$, then $\\frac{S_n}{n} \\rightarrow \\mu$ a.s. as $n \\rightarrow \\infty$.\n",
    "\n",
    "_Proof:_\n",
    "\n",
    "If the strong law of large numbers is true for non-negative numbers, then it's true for any random variable because $X_n=X_n^+-X_n^-$. i.e. $S_n/n=\\frac{\\sum{X_n^+}}{n}-\\frac{\\sum{X_n^-}}{n} \\rightarrow E[X_1^+]-E[X_1^-] = E{X}$ a.s. Therefore without loss of generality, we assume $X_n \\ge 0$.\n",
    "\n",
    "We want to first prove the theorem for a truncated version of itself, That is we want to first prove the following lemma: Let $Y_k = X_k\\mathbf{1}_{|X_k| \\le k}$, $S_n^*=\\sum_{k=1}^nY_k$, then $\\frac{S_n^*}{n} \\rightarrow \\mu$ a.s.\n",
    "\n",
    "Let first assume such lemma is true, then\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^{\\infty} P(X_k \\neq Y_k) = \\sum_{k=1}^{\\infty} P(X_1 \\gt k) \\lt \\int_{0}^{\\infty} P(X_1 > x) dx = E[X_1] \\lt \\infty\n",
    "$$\n",
    "\n",
    "$B = [X_k \\neq Y_k\\text{ i.o.}]$, $B^c=[X_k = Y_k\\text{ e.a.}]$. By Borel Cantelli Lemma, $P(B) = 0$,  $P(B^c) = 1$. Let $C=\\{\\omega: \\frac{S_n(w)-S_n^*(w)}{n} \\to 0\\}$, $C^c=\\{\\omega: \\frac{S_n(w)-S_n^*(w)}{n} \\not\\to 0\\}$. We want to prove $P(C)=1$. \n",
    "\n",
    "Suppose $\\omega \\in C^c \\cap B^c$. $\\omega \\in B^c$ indicates $X_k(w)=Y_k(w)$ for all but finitely many $k$. Suppose there are $M$ such $k$'s $k_1, k_2...k_M$. $\\lim\\limits_{n\\to\\infty}\\frac{\\sum\\limits_{k=1}^{n} (X_k-Y_k)}{n}=\\lim\\limits_{n\\to\\infty}\\frac{\\sum\\limits_{i=1}^{M} (X_{k_i}-Y_{k_i})}{n} = 0$, which contradicts to $\\omega \\in C^c$. We conclude that $C^c \\cap B^c = \\emptyset$, therefore the complement of $C^c$ which is $C$ contains $B^c$, that is $B^c \\subset C$. Because $P(B^c) = 1$, we have $P(C) = 1$, that is $\\frac{S_n(w)-S_n^*(w)}{n} \\to 0$ a.s.\n",
    "\n",
    "By the lemma below, we have $\\frac{S_n^*}{n} \\to \\mu$ a.s., therefore, $\\frac{S_n}{n} \\to \\mu$ a.s.\n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "### Lemma\n",
    "Let $Y_k = X_k\\mathbf{1}_{|X_k| \\le k}$, $S_n^*=\\sum_{k=1}^nY_k$, then $\\frac{S_n^*}{n} \\rightarrow \\mu$ a.s.\n",
    "\n",
    "_Proof:_\n",
    "\n",
    "Note that $Y_k$ are not identical and does not have the same mean.\n",
    "\n",
    "Since $Y_k \\rightarrow X_1$, by the dominated convergence theorem, $EY_k \\rightarrow EX_1=\\mu$.\n",
    "If $a_k \\rightarrow a$, $\\frac{\\sum_k^n{a_k}}{n} \\rightarrow a$, therefore, $\\frac{ES_n^*}{n} = \\frac{E[Y_1+...+Y_n]}{n} \\rightarrow EX_1=\\mu$.\n",
    "\n",
    "Pairwise independence of $X_k$ indicates pairwise indepedence of $Y_k$, therefore uncorrelated between $Y_k$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "var(S_n^*) = \\sum_{k=1}^n{var(Y_k)} \\le \\sum_{k=1}^n{EY_k^2} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Directly proving $S_n^* \\rightarrow \\mu$ a.s. is difficult. Instead, we first prove that for a subsequence of $\\{S_n^*; n \\ge 1\\}$, $\\{S_{k(n)}^*; n \\ge 1\\}$ converges: $S_{k(n)}^*/n \\rightarrow \\mu$ a.s. \n",
    "\n",
    "Because $Y_k \\ge 0$ we have $S_k^*$ is monotone non-decreasing, Then for $k(n) \\le m \\lt k(n+1)$, we have \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "S_{k(n)}^* \\le S_{m}^* \\le S_{k(n+1)}^* \\\\\n",
    "\\frac{S_{k(n)}^*}{k(n+1)} \\le \\frac{S_{k(n)}^*}{m} \\le \\frac{S_{m}^*}{m} \\le \\frac{S_{k(n+1)}^*}{m} \\le \\frac{S_{k(n+1)}^*}{k(n)} \\\\\n",
    "\\frac{k(n)}{k(n+1)}\\frac{S_{k(n)}^*}{k(n)} \\le \\frac{S_{m}^*}{m} \\le \\frac{k(n+1)}{k(n)}\\frac{S_{k(n+1)}^*}{k(n+1)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "If we can construct the subsequence $k(n)$ such that $k(n+1)/k(n)$ converges to a constant $\\alpha$, $k(n+1)/k(n) \\rightarrow \\alpha$, when $n \\rightarrow \\infty$, then the above inequality converges a.s. to:\n",
    "\n",
    "$$\n",
    "\\frac{1}{\\alpha}\\mu \\le \\liminf\\limits_{n \\rightarrow \\infty}\\frac{S_{m}^*}{m} \\le \\limsup\\limits_{n \\rightarrow \\infty}\\frac{S_{m}^*}{m} \\le \\alpha\\mu\n",
    "$$\n",
    "\n",
    "If we choose $\\alpha \\gt 1$ but arbitrary, then taking intersection of the sets above over $\\alpha$ for all $\\alpha$ that are rational numbers(therefore countable sets) gives us $\\lim\\limits_{m \\rightarrow \\infty}\\frac{S_m^*}{m} = \\mu$ a.s.\n",
    "\n",
    "So if we can find a subsequence $k(n)$ we are done proving the lemma.\n",
    "\n",
    "Now, let's find such subsequence. let $\\alpha \\gt 1$ be any number, let $k(n) = [a^n]$, it can be shown that $\\frac{k(n+1)}{k(m)} \\rightarrow \\alpha$. For any $\\epsilon \\gt 0$ if we can prove that the subsequence $\\sum_{n=1}^\\infty {P(\\big|S_{k(n)}^* - E[S_{k(n)}^*]\\big| \\gt \\epsilon{k(n)})} \\lt \\infty$ then by the Borel Cantelli lemma, $\\frac{\\big|S_{k(n)}^* - E[S_{k(n)}^*]\\big|}{k(n)} \\rightarrow 0$ almost surely. Because $\\frac{E[S_{k(n)}^*]}{k(n)} \\rightarrow \\mu$, we can conclude $\\frac{S_{k(n)}^*}{k(n)} \\rightarrow \\mu$ a.s. by then, we have found our subsequence. \n",
    "\n",
    "Now let's prove what we need to prove $\\sum_{n=1}^\\infty {P(\\big|S_{k(n)}^* - E[S_{k(n)}^*]\\big| \\gt \\epsilon{k(n)})} \\lt \\infty$. By the Chebyshev's inequality:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{n=1}^\\infty {P(\\big|S_{k(n)}^* - E[S_{k(n)}^*]\\big| \\gt \\epsilon{k(n)})} &\\le \\epsilon^{-2} \\sum_{n=1}^\\infty{k(n)^{-2} var(S_{k(n)}^*)} \\\\\n",
    "&= \\epsilon^{-2} \\sum_{n=1}^\\infty{k(n)^{-2}} \\sum_{m=1}^{k(n)} var(Y_m) \\\\\n",
    "&= \\epsilon^{-2} \\sum_{m=1}^{\\infty} var(Y_m) \\sum_{n:k(n) \\ge m}^\\infty{[a^n]^{-2}}  \\quad \\text{By Fubini Theorem }\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Note that for $n \\gt 1$, $[a^n] \\ge \\frac{a^n}{2}$ so $[a^n]^{-2} \\le 4a^{-2n}$. Moreover the geometric series is bounded by $\\sum_{n:k(n) \\ge m}^\\infty{a^{-2n}} \\le (1-\\alpha^{-2})^{-1}m^{-2}$. So $\\sum_{n:k(n) \\ge m}^\\infty{[a^n]^{-2}}$ is bounded: $\\sum_{n:k(n) \\ge m}^\\infty{[a^n]^{-2}} \\le 4\\sum_{n:k(n) \\ge m}^\\infty{a^{-2n}} \\le 4 (1-\\alpha^{-2})^{-1}m^{-2}$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{n=1}^\\infty {P(\\big|S_{k(n)}^* - E[S_{k(n)}^*]\\big| \\gt \\epsilon{k(n)})} &\\le \\epsilon^{-2} \\sum_{m=1}^{k(n)} var(Y_m) \\sum_{n:k(n) \\ge m}^\\infty{[a^n]^{-2}} \\\\\n",
    "&= \\epsilon^{-2} 4 (1-\\alpha^{-2})^{-1} \\sum_{m=1}^{\\infty} \\frac{var(Y_m)}{m^2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "If we could prove $\\sum_{m=1}^{\\infty} \\frac{var(Y_m)}{m^2}$ is also bounded, then we are done proving the condition needed for Borel Cantelli lemma and thus the a.s. convergence of the subsequence $S_{k(n)}^*$.\n",
    "\n",
    "Note that at the beginning we are assuming$X_m \\ge 0$, $Y_m \\ge 0$: $var(Y_m) \\le E(Y_m^2) = \\int_{0}^{\\infty} 2yP(Y_m \\gt y) dy \\le \\int_{0}^m 2yP(X_1 \\gt y) dy$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{m=1}^{\\infty} \\frac{var(Y_m)}{m^2} &\\le \\sum_{m=1}^{\\infty} \\frac{E(Y_m^2)}{m^2} \\le \\sum_{m=1}^{\\infty} {m^{-2}} \\int_{0}^{\\infty} \\mathbf{1}_{(y \\lt m)} 2yP(X_1 \\gt y) dy \\\\\n",
    "&= \\int_{0}^{\\infty} \\Big(2y \\sum_{m=1}^{\\infty} {m^{-2}}\\mathbf{1}_{(y \\lt m)}\\Big) P(X_1 \\gt y) dy \\quad \\text{By Fubini Theorem}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We want to show that $2y \\sum_{m=1}^{\\infty} {m^{-2}}\\mathbf{1}_{(y \\lt m)} = 2y \\sum_{m \\gt y}^{\\infty} {m^{-2}} \\lt 4$ bounded.\n",
    "\n",
    "First observe that when $y \\ge 2$, we have $\\sum_{m \\gt y}^{\\infty} {m^{-2}} \\le 2y \\int_{y-1} x^{-2} dx = (y-1)^{-1}$.\n",
    "\n",
    "- When $y \\ge 1$, the sum starts with $m=[y]+1 \\ge 2$, \n",
    "  and because $\\frac{y}{[y]} \\le 2$ for $y \\ge 1$ (maximum happens when $y$ is close to $2$), \n",
    "  so $2y \\sum_{m \\gt y} m^{-2} \\le 2y[m]^{-1} \\le 4$.\n",
    "- When $0 \\le y \\lt 1$, $2y \\sum_{m \\gt y} m^{-2} \\le 2 \\Big( 1+ \\sum_{m=2}^{\\infty} m^{-2} \\Big) \\le 4$.\n",
    "\n",
    "Now we concluded $2y \\sum_{m=1}^{\\infty} {m^{-2}}\\mathbf{1}_{(y \\lt m)} = 2y \\sum_{m \\gt y}^{\\infty} {m^{-2}} \\lt 4$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{m=1}^{\\infty} \\frac{var(Y_m)}{m^2} &\\le \\int_{0}^{\\infty} \\Big(2y \\sum_{m=1}^{\\infty} {m^{-2}}\\mathbf{1}_{(y \\lt m)}\\Big) P(X_1 \\gt y) \\\\\n",
    "&= \\int_{0}^{\\infty} \\Big(2y \\sum_{m \\gt y}^{\\infty} {m^{-2}}\\Big) P(X_1 \\gt y) \\\\\n",
    "&\\le 4\\int_{0}^{\\infty} P(X_1 \\gt y) \\\\\n",
    "&\\le 4E(X_1)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Back to our original inequalities:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{n=1}^\\infty {P(\\big|S_{k(n)}^* - E[S_{k(n)}^*]\\big| \\gt \\epsilon{k(n)})} &\\le \\epsilon^{-2} 4 (1-\\alpha^{-2})^{-1} \\sum_{m=1}^{\\infty} \\frac{var(Y_m)}{m^2} \\\\\n",
    "&\\le \\epsilon^{-2} 4 (1-\\alpha^{-2})^{-1} 4 E[X_1] \\lt \\infty\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "for all $\\epsilon \\gt 0$.\n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "\n",
    "## Weak law of large numbers\n",
    "\n",
    "### Theorem \n",
    "\n",
    "$P(\\liminf{A_n}) \\le \\liminf{P(A_n)} \\le \\limsup{P(A_n)} \\le P(\\limsup{A_n})$\n",
    "\n",
    "_Proof:_ Let $B_n= \\bigcap\\limits_{k=n}^{\\infty}A_k$. $B_n \\subset A_m$ for all $n,m$, $P(B_n) \\le P(A_m)$. $B_n \\uparrow \\liminf{A_m}$ indicates $P(B_n) \\uparrow P(\\liminf{A_n}) \\le \\liminf{P(A_n)}$. Similarly, Let $C_n= \\bigcup\\limits_{k=n}^{\\infty}A_k$ we can derive $\\limsup{P(A_n)} \\le P(\\limsup{A_n})$.\n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "### Theorem: Weak law of large numbers\n",
    "\n",
    "Let $X_1,X_2...$ be pairwise indepedent, identically distributed r.v. with $E|X_k| \\lt \\infty$. Let $EX_k=\\mu$, $S_n=\\sum_{k=1}^nX_k$, then $\\frac{S_n}{n} \\rightarrow \\mu$ in probability as $n \\rightarrow \\infty$.\n",
    "\n",
    "_Proof:_ $\\frac{S_n}{n} \\to \\mu$ a.s. is equivalent to $\\forall\\epsilon \\gt 0$, $P(\\big|\\frac{S_n}{n} - \\mu\\big| \\gt \\epsilon \\text{ i.o}) = P(\\limsup\\big[\\big|\\frac{S_n}{n} - \\mu\\big| \\gt \\epsilon\\big]) = 0$.\n",
    "\n",
    "$0\\le \\liminf\\limits_{n\\to\\infty}P(\\big| \\frac{S_n}{n}-\\mu\\big| \\gt \\epsilon) \\le \\limsup\\limits_{n\\to\\infty}P(\\big| \\frac{S_n}{n}-\\mu\\big| \\gt \\epsilon) \\le P(\\limsup\\big[\\big|\\frac{S_n}{n} - \\mu\\big| \\gt \\epsilon\\big]) = 0$, therefore $\\lim\\limits_{n\\to\\infty}P(\\big| \\frac{S_n}{n}-\\mu\\big| \\gt \\epsilon) = 0$.\n",
    "\n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "Conclusion: Strong law of large number guarantees weak law of large numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cea453-bba7-4e50-bf71-de2dbc7209b7",
   "metadata": {},
   "source": [
    "## Tail sigma field\n",
    "\n",
    "**Video lecture: https://youtu.be/u7oWRjeGlYM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba35646-d2ef-401b-a05c-bfe87bb3c6d7",
   "metadata": {},
   "source": [
    "### Definitions\n",
    "\n",
    "- Let $\\mathcal{G}_{n}^{\\infty} = \\sigma(X_n,X_{n+1},...)$ the smallest sigma field to which all $X_m$, $m \\le n$ are measurable. $\\sigma(X_n,X_{n+1},...)$ is equivalent to $\\sigma(\\sigma(X_n),\\sigma(X_{n+1}),...)$.\n",
    "\n",
    "    Let $\\mathcal{T} = \\cap_{n=1}^{\\infty}\\mathcal{G}_{n}^{\\infty}$. The smallest sigma field that $X_n,X_{n+1},...$ are measurable for any number $n$. $\\mathcal{T}$ is called the __tail $\\sigma$-field__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c327ba-cd80-471e-9d8d-a239aa392fae",
   "metadata": {},
   "source": [
    "### Examples of Tail $\\sigma$-field\n",
    "\n",
    "- $E=[X_n \\lt a \\text{ i.o.}] \\in \\mathcal{T}$: \n",
    "    \n",
    "    If $E$ belongs to $\\mathcal{T}$, then $E$ must belongs to every $\\sigma(X_n, X_{n+1},...)$ for all $n$, which is true because: $E = \\cap_{m=1}^{\\infty}\\cup_{n=m}^{\\infty}\\{X_n \\lt a\\}$. If we let $A_m = \\cup_{n=m}^{\\infty}\\{X_n \\lt a\\}$. For any fixed $m$, $A_m \\in \\sigma(X_k, X_{k+1},...)$ for any $1 \\le k \\le m$. Since $A_m$ is a decreasing set, and $E = \\lim_{m\\to\\infty}A_m$, we have $E \\in \\sigma(X_k, X_{k+1},...)$ for all $k \\in \\mathbf{N}^{+}$.\n",
    "- $E^c=[X_n \\ge a \\text{ e.a.}] \\in \\mathcal{T}$: \n",
    "    \n",
    "    Since its a complement of $\\text[X_n \\lt a \\text{ i.o}]$.\n",
    "- $E = [\\lim_{n\\to\\infty}S_n \\text{ converges}] \\in \\mathcal{T}$: \n",
    "    \n",
    "    $\\lim{S_n(\\omega)}$ converges iff $\\limsup{S_n(\\omega)} = \\liminf{S_n(\\omega)}$, or, for every $\\epsilon$ there exist an $N$ s.t. for all $n \\ge N$, $|\\sup_{m \\ge n}S_m(\\omega) - \\inf_{m \\ge n}{S_m(\\omega)}| \\lt \\epsilon$. \n",
    "\n",
    "    If we iterate the $\\epsilon$ using rational numbers, then $E$ is equivalent to $E = \\bigcap\\limits_{\\epsilon \\in \\mathbf{Q}}\\bigcup\\limits_{N=1}^{\\infty}\\bigcap\\limits_{n=N}^{\\infty}\\big[\\omega: |\\sup_{m \\ge n}S_m(\\omega) - \\inf_{m \\ge n}S_m(\\omega)| \\lt \\epsilon\\big]$ which is a countable intersection of infinitly often events that belongs to the tail $\\sigma$-field. \n",
    "    \n",
    "    Why $\\bigcup\\limits_{N=1}^{\\infty}\\bigcap\\limits_{n=N}^{\\infty}\\big[\\omega: \\big|\\sup_{m \\ge n}S_m(\\omega) - \\inf_{m \\ge n}S_m(\\omega)\\big| \\lt \\epsilon\\big] \\in \\mathcal{T}$? Because $\\big[\\omega: \\big|\\sup_{m \\ge n}S_m(\\omega) - \\inf_{m \\ge n}S_m(\\omega)\\big| \\lt \\epsilon\\big] = \\big[\\omega: \\big|\\sup\\limits_{m \\ge n}\\sum_{i=n}^{m}X_{i}(\\omega) - \\inf\\limits_{m \\ge n}\\sum_{i=n}^{m}X_{i}(\\omega)\\big| \\lt \\epsilon\\big] \\in \\sigma(X_n,X_{n+1},...)$.\n",
    "    \n",
    "    In the mean time, $E^c = [\\lim_{n\\to\\infty}S_n \\text{ diverges}] \\in \\mathcal{T}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b94d7be-a5d0-445e-aea3-bb77c7e0a7a9",
   "metadata": {},
   "source": [
    "One rule of thumb to check if $E$ is in the tail $\\sigma$-field is to check if removing finte number of $X_{k_1},...,X_{k_m}$ would change the occurence of the event. For example, for any $\\omega \\in E$, does the event still occurs if $X_{k_1},...,X_{k_m}$ are removed from the $S_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ff084-b2cc-48cb-bbbc-b16512ade6e1",
   "metadata": {},
   "source": [
    "- $E = [\\limsup_{n\\to\\infty}S_{1}^{n} \\gt 0 ] \\notin \\mathcal{T}$: \n",
    "\n",
    "    $S_m^n \\equiv \\sum_{k=m}^{n} X_k$. Let $A,B \\in \\mathcal{R}$ disjoint and $A \\cup B \\neq \\Omega$. Let $X_1 = \\mathbf{1}_{A}$, $X_n = \\mathbf{1}_{B}$ for $n \\ge 2$. Therefore $E = A \\cup B$. For any $\\omega \\in A$ we have $\\limsup{S_{1}^{n}} = 1 \\gt 0$, but $\\limsup{S_k^{n}} = 0$ for all $k \\gt 1$, which indicates $E \\not\\in \\sigma(X_k, X_{k+1},...) = \\sigma(B)$ for all $k \\gt 1$.\n",
    "    \n",
    "- $E = [\\liminf_{n\\to\\infty}S_{1}^{n} > 0 ] \\notin \\mathcal{T}$: Same reasoning.\n",
    "    \n",
    "- $E = [\\limsup_{n\\to\\infty}S_{1}^{n} = c ] \\notin \\mathcal{T}$ for some constant $c$: Same reasoning.\n",
    "\n",
    "- $E = [\\liminf_{n\\to\\infty}S_{1}^{n} = c ] \\notin \\mathcal{T}$ for some constant $c$: Same reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b7174e-8350-4fbe-926b-f059f0a888c8",
   "metadata": {},
   "source": [
    "\n",
    "- $E = [\\lim_{n\\to\\infty}{\\frac{S_{1}^{n}}{n}} = c] \\in \\mathcal{T}$ for some constant $c$: \n",
    "\n",
    "    For any $\\epsilon \\in E$, $\\lim_{n\\to\\infty}{\\frac{S_{1}^{n}}{n}} = c$ is equivalent to $\\lim_{n\\to\\infty}{\\frac{S_{1}^{K-1}}{n}}+\\lim_{n\\to\\infty}{\\frac{S_{K}^{n}}{n}} = c$ for any fix $K$. Therefore $E \\in \\sigma(X_K, X_{K+1},...)$ for any $K$. We have $E \\in \\mathcal{T}$.\n",
    "    \n",
    "- $E = [\\lim_{n\\to\\infty}{\\frac{S_{1}^{n}}{b_n}} = c] \\in \\mathcal{T}$ for some constant $c$ and $b_n \\to \\infty$: Same reasoning as above.\n",
    "\n",
    "- $E = [\\lim_{n\\to\\infty}{\\frac{S_{1}^{n}}{b_n}} < c] \\in \\mathcal{T}$ for some constant $c$ and $b_n \\to \\infty$: Same reasoning as above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df1eff-30c9-42f2-bed5-0f9261f8d4ac",
   "metadata": {},
   "source": [
    "What tail $\\sigma$-field event telling us is that, it does not depends on the finite number of sigma-fields. Removing or changing finite number of random variables does not affect the occurence of the event."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8b3b22-d03a-4cb4-bac0-c859750c87ee",
   "metadata": {},
   "source": [
    "## Independence of Sigma fields\n",
    "\n",
    "### Definitions\n",
    "\n",
    "- Sigma fields $\\mathcal{F_1}, \\mathcal{F_2},...,\\mathcal{F_n}$  are independent iff for any $A_i \\in \\mathcal{F_i}$ we have $P(\\cap_{i=1}^nA_i) = \\prod_{i=1}^{n}P(A_i)$.\n",
    "- Random variables $X_1, ..., X_n$ are independent iff for any $B_i \\in \\mathcal{R}$ we have $P(\\cap_{i=1}^n\\{X_i \\in B_i\\}) = \\prod_{i=1}^{n}P(X_i \\in B_i)$\n",
    "- We say $\\mathcal{A}$ is a __$\\pi$-system__ if it's closed under intersection. i.e. If $A,B \\in \\mathcal{A}$ then $A \\cap B \\in \\mathcal{A}$.\n",
    "- We say $\\mathcal{L}$ is a __$\\lambda$-system__ if\n",
    "    1. $\\Omega \\in \\mathcal{L}$\n",
    "    2. If $A,B \\in \\mathcal{L}$ and $A \\subset B$ then $B-A \\in \\mathcal{L}$\n",
    "    3. If $A_n \\in \\mathcal{L}$ and $A_n \\uparrow A$ then $A \\in \\mathcal{L}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aced34a4-6fbd-4e9e-a38e-b84be1277567",
   "metadata": {},
   "source": [
    "### Independent $\\pi$-system Theorem\n",
    "\n",
    "Suppose $\\mathcal{A_1},...,\\mathcal{A_n}$ are indepdent $\\pi$-systems. Then $\\sigma(\\mathcal{A_1}), ..., \\sigma(\\mathcal{A_n})$ are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0333ac10-9d85-4f98-a642-962f389b1627",
   "metadata": {},
   "source": [
    "### Corollary\n",
    "\n",
    "If for all $x_1,...,x_n \\in (-\\infty, \\infty]$,\n",
    "\n",
    "$$\n",
    "P(X_1\\le x_1,...,X_n\\le x_n) = \\prod_{i=1}^{n}P(X_i\\le x_i)\n",
    "$$\n",
    "\n",
    "Then $X_1,...,X_n$ are independent.\n",
    "\n",
    "_Proof:_\n",
    "\n",
    "Let $\\mathcal{A}_i = \\{ X_i \\le r_{X_i} : r_{X_i} \\in \\mathbf{R}\\}$. $A,B \\in \\mathcal{A}_i$ indicates $A\\cap B \\in \\mathcal{A}_i$, so $\\mathcal{A}_i$ is a $\\pi$-system. $\\sigma(\\mathcal{A}_i) = \\sigma(X_i)$, by the theorem above, we have $X_1,...,X_n$ are independent.\n",
    "\n",
    "$\\blacksquare$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a844451-9a48-46e1-8eda-53d506c75fac",
   "metadata": {},
   "source": [
    "### Corollary\n",
    "\n",
    "Suppose $\\mathcal{F_{ij}}$, $1\\le i \\le n$, $1, \\le j \\le m(i)$ are independent. Let $\\mathcal{G_i} = \\sigma(\\cup_{j}F_{i,j})$, then $\\mathcal{G_1},...,\\mathcal{G_n}$ are independent.\n",
    "\n",
    "_Proof:_\n",
    "\n",
    "Let $\\mathcal{A_i}$ be the collection of the form $\\cap_j A_{ij}$ where $A_{ij} \\in \\mathcal{F_{ij}}$. $\\mathcal{A_i}$ is a $\\pi$-system that contains $\\Omega$ and contains $\\cup_j\\mathcal{F_{ij}}$ (Choose one and only one j that is not $\\Omega$ and let others all be $\\Omega$, this indicates that every set in $F_{ij}$ belongs to $\\mathcal{A_i}$ for all $\\mathcal{F_{ij}}$), so Independent $\\pi$-system theorem implies $\\sigma(\\mathcal{A_i}) = \\sigma(\\cup_{j}F_{i,j})$ are independent.\n",
    "\n",
    "$\\blacksquare$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370971b1-6ffa-449b-a9fd-dd75141f2a11",
   "metadata": {},
   "source": [
    "### Corollary\n",
    "\n",
    "Suppose $X_{ij}$, $1 \\le i \\le n$, $1 \\le j \\le m(i)$ are independent. Let $f_i:\\mathbf{R}^{m(i)} \\to \\mathbf{R}$  are measurable functions, then $f_i(X_{1,1},...,X_{1,m(i)})$ are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f8296f-856c-43e4-afdf-ec9ca3d764a7",
   "metadata": {},
   "source": [
    "_Proof:_\n",
    "\n",
    "Let $\\mathcal{F_{ij}} = \\sigma(X_{ij})$, $\\mathcal{G_i} = \\sigma(\\cup_{j}\\mathcal{F_{ij}})$. Since $f_i(X_{i,1},...,X_{i,m(i)}) \\in \\mathcal{G_i}$, the result follows from corrollary above.\n",
    "\n",
    "$\\blacksquare$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b188ce6a-6830-4b43-ba23-c13140b62ff0",
   "metadata": {},
   "source": [
    "## 0-1 laws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43edfc26-37da-404d-85f8-57713f1a2449",
   "metadata": {},
   "source": [
    "### Theorem Kolmogorov's 0-1 law\n",
    "\n",
    "**Video lecture: https://youtu.be/LGwkGa9X4do**\n",
    "\n",
    "If $X_1, X_2,...$ are indepdent and $A\\in\\mathcal{T}$ then $P(A) = 0$ or $P(A) = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f88c66-6b24-40c5-a21e-4f3c83e55b86",
   "metadata": {},
   "source": [
    "_Proof:_\n",
    "\n",
    "The idea is to prove that $A$ is indepdent of itself. By then, we get $P(A \\cap A) = P(A)^2$, hence $P(A) = 0$ or $P(A) = 1$.\n",
    "\n",
    "Note that $\\sigma(X_1,...,X_k)$ and $\\sigma(X_{k+1},...)$ are indepdent, and $\\mathcal{T} \\subset \\sigma(X_{k+1},...)$ for all $k$. Therefore, $\\mathcal{T}$ and $\\sigma(X_1,...,X_k)$ are indepdent for all $k$.\n",
    "\n",
    "$\\sigma(X_1,X_2,...) \\subset \\sigma(\\cup_k\\sigma(X_1,...,X_k))$ and $\\mathcal{T}$ are indepdent.\n",
    "\n",
    "Since $\\mathcal{T} \\subset \\sigma(X_1, X_2,...)$, if $A \\in \\mathcal{T}$, $A$ also $A\\in \\sigma(X_1, X_2,...)$. So we concluded $A$ is indepedent of itself.\n",
    "\n",
    "$\\blacksquare$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
